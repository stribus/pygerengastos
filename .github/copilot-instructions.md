# Copilot Instructions - Sistema Gerenciamento de Gastos Mensais

## Arquitetura do Projeto

Este √© um sistema de gerenciamento de despesas mensais em Python que implementa um pipeline completo:
1. **Web Scraping**: Extrai NFC-e do site da SEFAZ-RS via POST request com cabe√ßalhos espec√≠ficos
2. **Classifica√ß√£o H√≠brida**: Usa busca sem√¢ntica (ChromaDB + SentenceTransformers) com fallback para LLM (Gemini via LiteLLM)
3. **Persist√™ncia**: SQLite3 com schema dimensional (datas, estabelecimentos, produtos, categorias)
4. **Interface**: Streamlit com 3 abas (Home/Importa√ß√£o/An√°lise) e navega√ß√£o com redirecionamento

## Stack Tecnol√≥gico

- **Frontend**: Streamlit com `st.session_state` para navega√ß√£o e cache
- **Backend**: Python 3.13.1
- **IA/ML**: 
  - Busca sem√¢ntica: ChromaDB 1.3.5 + SentenceTransformers 5.1.2 (modelo `all-MiniLM-L6-v2`)
  - LLM: LiteLLM com modelos configur√°veis via TOML (padr√£o: `gemini/gemini-2.5-flash-lite`)
  - Configura√ß√£o: `config/modelos_llm.toml` com carregamento lazy + background thread
- **Banco de Dados**: SQLite3 (nativo Python) com schema normalizado e views agregadas
- **Web Scraping**: httpx + BeautifulSoup4
- **Ambiente**: `uv` como gerenciador de pacotes (use `uv pip`, `uv add`, nunca `pip install` direto)
- **Logging**: Sistema centralizado via `src/logger.py` com RotatingFileHandler em `logs/app.log`

## Fluxo de Classifica√ß√£o H√≠brida (CR√çTICO)

O sistema usa **classifica√ß√£o sem√¢ntica priorit√°ria** com fallback para LLM:

1. **Busca Sem√¢ntica (ChromaDB)**: Para cada item, busca produtos similares por embedding
   - Se `score >= 0.82`: reutiliza `produto_id`, `categoria`, `nome_base`, `marca_base` (origem: `chroma-cache`)
   - Embeddings gerados com `all-MiniLM-L6-v2` e armazenados em `data/chroma/`
   
2. **Fallback LLM (Gemini)**: Apenas para itens sem match sem√¢ntico
   - Modelos configur√°veis em `config/modelos_llm.toml` (Gemini, LLaMA, Kimi, GPT-4o)
   - Prioridade definida pela ordem no TOML ou ajust√°vel na UI
   - Retorna: categoria + confian√ßa + produto_nome + produto_marca + justificativa
   - Origem: `gemini-litellm` (ou outro modelo conforme configura√ß√£o)

3. **Persist√™ncia Autom√°tica**: Ambos os fluxos atualizam SQLite3 e registram embeddings via `_registrar_alias_produto()`

**Exemplo de implementa√ß√£o**: Ver `src/classifiers/__init__.py::classificar_itens_pendentes()` e testes em `tests/test_semantic_integration.py`

## Por que SQLite3?

O projeto **migrou de DuckDB para SQLite3** (dezembro/2025) pelos seguintes motivos:

- **Melhor suporte a UPDATE com Foreign Keys**: SQLite3 permite `PRAGMA foreign_keys = OFF` tempor√°rio, resolvendo limita√ß√µes do DuckDB ao atualizar colunas em tabelas com FKs apontando para elas
- **Maturidade OLTP**: Mais est√°vel para opera√ß√µes frequentes de insert/update (CRUD t√≠pico)
- **Portabilidade**: Arquivo √∫nico `.db` sem depend√™ncias externas, nativo no Python (n√£o precisa instalar pacote)
- **Performance adequada**: Volume de dados (notas fiscais pessoais) n√£o justifica complexidade do DuckDB

## Configura√ß√£o de Modelos LLM (IMPORTANTE)

### Carregamento Lazy + Background Thread

Os modelos LLM s√£o carregados de forma **n√£o-bloqueante** usando pattern de lazy loading com background concurrency:

```python
# main.py - Carregamento iniciado durante bootstrap do Streamlit
from src.classifiers.llm_classifier import iniciar_carregamento_background
iniciar_carregamento_background()  # Retorna Future, executa em thread

# Uso posterior - aguarda carregamento se necess√°rio, usa cache se dispon√≠vel
from src.classifiers.llm_classifier import obter_modelos_carregados
modelos = obter_modelos_carregados(aguardar=True)  # 5s timeout, fallback on failure
```

**Caracter√≠sticas:**
- **Thread-safe**: Double-checked locking para performance em sess√µes concorrentes
- **Cache em mem√≥ria**: Uma vez carregados, reutiliza inst√¢ncias sem re-parsing
- **Fallback autom√°tico**: Se TOML malformado/ausente, usa configura√ß√£o hardcoded do Gemini
- **Timeout**: 5s (constante `BACKGROUND_LOAD_TIMEOUT`) antes de fallback

### Arquivo de Configura√ß√£o

`config/modelos_llm.toml` centraliza configura√ß√µes de todos os modelos:

```toml
[[modelos]]
nome = "gemini/gemini-2.5-flash-lite"
nome_amigavel = "Gemini 2.5 Flash Lite (Padr√£o)"
api_key_env = "GEMINI_API_KEY"
max_tokens = 8000
max_itens = 50
timeout = 30.0

# Opcional: par√¢metros espec√≠ficos do modelo
[modelos.extra_body.chat_template_kwargs]
thinking = false
```

**Campos obrigat√≥rios**: `nome`, `api_key_env`  
**Campos opcionais**: `max_tokens`, `max_itens`, `timeout`, `nome_amigavel`, `extra_body`

### Tratamento de Erros TOML

O sistema √© **resiliente a erros de configura√ß√£o**:

| Erro | Comportamento |
|------|---------------|
| Sintaxe TOML inv√°lida | Loga erro + usa fallback Gemini |
| Campo obrigat√≥rio ausente | Pula modelo inv√°lido + carrega v√°lidos |
| Nenhum modelo v√°lido | Usa fallback Gemini hardcoded |
| Arquivo n√£o encontrado | Loga erro + usa fallback Gemini |

**Fallback Gemini** (`_obter_modelos_fallback()`):
```python
ModeloConfig(
    nome="gemini/gemini-2.5-flash-lite",
    api_key_env="GEMINI_API_KEY",
    max_tokens=8000,
    max_itens=50,
    timeout=30.0,
    nome_amigavel="Gemini 2.5 Flash Lite (Fallback)"
)
```

### Hot-Reload (Sem Reiniciar App)

Recarregar configura√ß√µes ap√≥s editar TOML:

**Via UI**: "Importar nota" ‚Üí "‚öôÔ∏è Configura√ß√µes de LLM" ‚Üí "üîÑ Recarregar modelos"

**Via c√≥digo**:
```python
from src.classifiers.llm_classifier import recarregar_modelos
modelos = recarregar_modelos()  # Invalida cache + recarrega TOML
```

### Helpers para Acessar Modelos

**SEMPRE use fun√ß√µes helpers** (nunca acesse `DEFAULT_MODELOS` diretamente):

```python
from src.classifiers.llm_classifier import (
    obter_modelos_disponiveis,      # Lista de IDs: ["gemini/...", "nvidia_nim/..."]
    obter_modelos_com_nomes_amigaveis,  # Dict {nome_amigavel: model_id}
    obter_modelos_carregados        # Lista de ModeloConfig (com cache)
)

# UI de sele√ß√£o
modelos_dict = obter_modelos_com_nomes_amigaveis()
modelo_selecionado = st.selectbox("Modelo", options=list(modelos_dict.keys()))
model_id = modelos_dict[modelo_selecionado]
```

### Testes de Configura√ß√£o

Testes abrangentes em `tests/test_llm_config_loading.py` (17 testes):
- TOML malformado ‚Üí fallback
- Campos obrigat√≥rios ausentes ‚Üí pula modelo
- Carregamento concorrente (10 threads) ‚Üí thread-safe
- Timeout em background loading ‚Üí fallback
- Cache e invalida√ß√£o ‚Üí reuso correto
- Hot-reload ‚Üí atualiza√ß√£o sem restart

## Conven√ß√µes Espec√≠ficas do Projeto

### Nomenclatura
- **Dom√≠nio**: Portugu√™s BR (`salvar_nota()`, `categoria_confirmada`, `emitente_nome`)
- **T√©cnico**: Ingl√™s OK para padr√µes Python (`logger`, `dataclass`, `db_path`)
- **Documenta√ß√£o**: Sempre em portugu√™s

### Integra√ß√£o com SEFAZ-RS (src/scrapers/receita_rs.py)
```python
# POST para endpoint oficial com cabe√ßalhos simulando navegador
NFCE_POST_URL = "https://www.sefaz.rs.gov.br/ASP/AAE_ROOT/NFE/SAT-WEB-NFE-NFC_2.asp"
# Payload: HML=false, chaveNFe=<44 d√≠gitos>, Action=Avan√ßar
# Referer: .../SAT-WEB-NFE-NFC_1.asp?chaveNFe=<chave>
# Salva HTML em: data/raw_nfce/nfce_<chave>.html
```

### Logging Padronizado
```python
from src.logger import setup_logging
logger = setup_logging(__name__)  # Usa nome do m√≥dulo
# Logs v√£o para logs/app.log (rotating 5MB, 3 backups) + console
```

## Ambiente de Desenvolvimento

### Setup Inicial (Windows PowerShell)
```powershell
# Ativar ambiente virtual
.\.venv\Scripts\Activate.ps1

# Instalar depend√™ncias (SEMPRE use uv)
uv sync  # Ou: uv pip install -r requirements.txt

# Rodar aplica√ß√£o
streamlit run main.py

# Rodar testes
pytest  # Filtra warnings do pydantic/litellm via pyproject.toml
```

### ‚ö†Ô∏è CR√çTICO: Gerenciamento de Pacotes
- **NUNCA** use `pip install` diretamente
- **SEMPRE** use `uv add <pacote>` para adicionar depend√™ncias
- O `uv` atualiza automaticamente `pyproject.toml` e `uv.lock`

### Estrutura Real do Projeto
```
‚îú‚îÄ‚îÄ main.py                      # Entry point Streamlit com navega√ß√£o via session_state
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ modelos_llm.toml         # Configura√ß√£o de modelos LLM (Gemini, LLaMA, Kimi, GPT-4o)
‚îÇ   ‚îî‚îÄ‚îÄ README.md                # Documenta√ß√£o de configura√ß√£o e hot-reload
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ logger.py                # Logging centralizado (RotatingFileHandler)
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ receita_rs.py        # Scraper SEFAZ-RS + dataclasses (NotaFiscal, NotaItem)
‚îÇ   ‚îú‚îÄ‚îÄ classifiers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # classificar_itens_pendentes() - orquestra sem√¢ntica + LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py        # ChromaDB: upsert_produto_embedding(), buscar_produtos_semelhantes()
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_classifier.py    # LLMClassifier + lazy loading + background thread + cache
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py          # SQLite3: salvar_nota(), registrar_classificacao_itens(), views
‚îÇ   ‚îî‚îÄ‚îÄ ui/
‚îÇ       ‚îú‚îÄ‚îÄ home.py              # Dashboard com KPIs e gr√°ficos mensais
‚îÇ       ‚îú‚îÄ‚îÄ importacao.py        # Input chave NFC-e + classifica√ß√£o autom√°tica + reload LLM
‚îÇ       ‚îî‚îÄ‚îÄ analise.py           # Edi√ß√£o de categoria/produto + hist√≥rico de revis√µes
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ gastos.db                # Banco principal (SQLite3)
‚îÇ   ‚îú‚îÄ‚îÄ categorias.csv           # Seed de categorias (carregado via seed_categorias_csv())
‚îÇ   ‚îú‚îÄ‚îÄ chroma/                  # √çndice de embeddings
‚îÇ   ‚îî‚îÄ‚îÄ raw_nfce/                # HTMLs brutos das notas (debug)
‚îú‚îÄ‚îÄ tests/                       # Testes com pytest + fixtures p√∫blicas
‚îÇ   ‚îú‚îÄ‚îÄ test_llm_config_loading.py  # 17 testes de lazy loading + concurrency + fallback
‚îÇ   ‚îî‚îÄ‚îÄ test_modelos_llm_toml.py    # Testes de sintaxe TOML (sub-tabela vs inline)
‚îú‚îÄ‚îÄ build.ps1                    # Script de build para distribui√ß√£o
‚îî‚îÄ‚îÄ pyproject.toml               # Config uv + pytest (filtra warnings)
```

## Schema SQLite3 (Dimensional)

### Tabelas Principais
- `notas`: Cabe√ßalho da NFC-e (chave_acesso PK, estabelecimento_id FK, emissao_data)
- `itens`: Produtos da nota (chave_acesso + sequencia PK, produto_id FK, categoria_sugerida, categoria_confirmada)
- `produtos`: Entidade can√¥nica (id PK, nome_base, marca_base, categoria_id FK)
- `aliases_produtos`: Mapeia descri√ß√µes originais ‚Üí produto_id (texto_original UNIQUE)
- `categorias`: Lista de categorias (id PK, grupo, nome)
- `estabelecimentos`: Emitentes normalizados (cnpj_normalizado UNIQUE)
- `datas_referencia`: Dimens√£o temporal (data_iso PK, ano_mes, nome_mes PT-BR)

### Tabelas de Auditoria
- `classificacoes_historico`: Log de todas as classifica√ß√µes (chroma-cache, gemini-litellm, revisao-manual)
- `revisoes_manuais`: Ajustes feitos por usu√°rios (usuario, observacoes, confirmado)

### Views
- `vw_itens_padronizados`: Join completo com datas + estabelecimentos + categorias (usada pelos dashboards)

## Padr√µes de Implementa√ß√£o

### Transa√ß√µes SQLite3
```python
from src.database import conexao, salvar_nota

# SEMPRE use context manager
with conexao() as con:
    con.execute("BEGIN TRANSACTION")
    try:
        # opera√ß√µes...
        con.execute("COMMIT")
    except Exception:
        con.execute("ROLLBACK")
        raise
```

### Navega√ß√£o Streamlit
```python
# Redirecionar entre abas
st.session_state["redirecionar_menu"] = "Analisar notas"
st.rerun()

# Passar dados entre telas
st.session_state["nota_em_revisao"] = chave_acesso
```

### Classifica√ß√£o Manual vs Autom√°tica
```python
# Sugest√£o (categoria_sugerida):
classificar_itens_pendentes(confirmar=False)

# Confirma√ß√£o (categoria_confirmada + produto_id):
registrar_revisoes_manuais([...], confirmar=True, usuario="Jo√£o")
```

## Comandos de Build/Distribui√ß√£o

```powershell
# Build completo com venv empacotada
.\build.ps1 -PackageName pygerengastos

# Build sem compactar
.\build.ps1 -SkipZip

# Build com dados brutos (para debug)
.\build.ps1 -IncludeRawData
```

## Considera√ß√µes de Performance

- **ChromaDB**: √çndice regenerado automaticamente em `upsert_produto_embedding()` ap√≥s cada classifica√ß√£o
- **SQLite3**: Queries r√°pidas via views materializadas (`vw_itens_padronizados`)
- **LLM**: 
  - Apenas chamado para itens sem match sem√¢ntico (economia de tokens/custo)
  - Modelos carregados em background thread (n√£o bloqueia UI)
  - Cache em mem√≥ria thread-safe (evita re-parsing TOML)
  - Fallback autom√°tico para Gemini em caso de erro (resiliente)
- **HTML Cache**: `data/raw_nfce/` facilita re-parsing sem re-scraping

## Debugging/Troubleshooting

- **Logs**: Sempre consulte `logs/app.log` primeiro
- **Embeddings**: Se busca sem√¢ntica falha, delete `data/chroma/` e reimporte notas
- **LLM**: 
  - Verifique `GEMINI_API_KEY` (ou outra chave) no `.env` (carregado via `python-dotenv`)
  - Erros de configura√ß√£o: veja `logs/app.log` para detalhes de parsing TOML
  - Recarregue modelos via UI se editou `config/modelos_llm.toml`
  - Se TOML malformado, sistema usa fallback Gemini automaticamente
- **Testes**: Fixture p√∫blica em `.github/xmlexemplo.xml` garante testes determin√≠sticos
- **Debug de produtos**: Use `debug_product_update.py` para inspecionar `produto_id` e aliases
- **Configura√ß√£o LLM**:
  - Teste sintaxe TOML: `python -m tomllib config/modelos_llm.toml`
  - Veja modelos carregados: `tests/test_llm_config_loading.py::test_arquivo_modelos_llm_atual`
  - Hot-reload: use bot√£o UI ou `recarregar_modelos()` em c√≥digo